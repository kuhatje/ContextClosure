\documentclass{beamer}
\usetheme{Madrid}
\usepackage{graphicx}
\title{Context Closure: Concise Overview}
\author{}
\date{\today}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Motivation}
  \begin{itemize}
    \item Documentation depends on code, tickets, and discussions; signals are unbounded.\pause
    \item LLM context windows (and human attention) are bounded.\pause
    \item Scalability: we must pick the most valuable, self-contained context slice, not dump everything.\pause
    \item Goal: organize signals to maximize documentation value within hard context limits.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Scalability $\Rightarrow$ Graph + Optimal Closure}
  \begin{itemize}
    \item Chunk the data (messages, issues, PRs, doc gaps) into nodes; remove duplication via dependencies (edges: $u \rightarrow v$ means $u$ needs $v$).\pause
    \item Assign utility weight per chunk; higher = more value for next doc update.\pause
    \item Select $k$ chunks that form a closure (no outgoing edges), maximizing total weight.\pause
    \item This is exactly the \textbf{maximum-weight closure} problem.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Optimal Closure Primer}
  \begin{itemize}
    \item Given a directed graph with weights, find a closed subset (no outgoing edges) with maximum total weight.\pause
    \item Solvable via min-cut reduction (polynomial time).\pause
    \item Our use: pick the best self-contained context under size/budget constraints.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example 1 (tiny)}
  \begin{itemize}
    \item Nodes: $A(5)$, $B(3)$, $C(-2)$; edges: $A \rightarrow B$, $B \rightarrow C$.\pause
    \item Closures: $\{A,B,C\}$ (sum $6$), $\{B,C\}$ (sum $1$), $\{C\}$ (sum $-2$).\pause
    \item Optimal: $\{A,B,C\}$ with weight $6$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example 2 (medium)}
  \begin{itemize}
    \item Nodes: $A(8), B(7), C(-4), D(5), E(-3)$.\pause
    \item Edges: $A \rightarrow B$, $A \rightarrow C$, $B \rightarrow D$, $D \rightarrow E$.\pause
    \item Candidate closures: $\{A,B,D,E,C\}$ (sum $13$), $\{A,B,D\}$ (sum $20$), $\{B,D\}$ (sum $12$).\pause
    \item Optimal: $\{A,B,D\}$ with weight $20$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example 3 (larger)}
  \begin{itemize}
    \item Nodes: 10+ with mixed positive/negative weights; layered dependencies.\pause
    \item Edges form multiple chains and cross-links; removing a negative node may require dropping high-value parents.\pause
    \item Visual takeaway: as size grows, closures are non-trivial to eyeball; algorithmic solution needed.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Generalization}
  \begin{itemize}
    \item $k$ need not be an LLM context limit; it can be any resource budget (time, people, memory).\pause
    \item Weights can encode any utility (task priority, revenue, risk).\pause
    \item Closure selection still yields the highest-value, self-contained subset for the chosen budget.\pause
    \item LLM-driven docs are one special case; the method applies to broader task selection.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Drawbacks \& Mitigations}
  \begin{itemize}
    \item Dependency detection may be incomplete or noisy $\rightarrow$ improve link extraction, allow human corrections.\pause
    \item Weighting may be biased or stale $\rightarrow$ add recency decay, source trust, feedback loops.\pause
    \item Graph churn and scale $\rightarrow$ incremental updates, caching, and persisted graphs.\pause
    \item Empty or sparse edges $\rightarrow$ fallback visualization only (not for optimization), keep optimization on real edges.\pause
  \end{itemize}
\end{frame}

\end{document}
